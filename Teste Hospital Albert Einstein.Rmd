---
title: "Teste Hospital Albert Einstein"
author: "Caroline - 145687"
date: "11 de dezembro de 2019"
output: pdf_document
---


O banco de dados fornecido possui três variáveis numéricas e uma variável categória. Esta última é a variável de interesse e possui como resposta "0" ou "1", ou seja, a partir das outras três variáveis, o interesse é saber a qual categoria cada observação pertence, se é um "zero" ou se é um "um".


Leitura do banco de dados:

```{r setup, include = FALSE}

df_points <- read.delim("df_points.txt", row.names = 1, quote = "", stringsAsFactors = FALSE)

```


Antes de qualquer modelagem, uma análise inicial é feita na base de dados com a finalidade de explorar os dados fornecidos e procurar alguma relação entre as variáveis.


Análise exploratória:

```{r setup, include = FALSE}

summary(df_points)
sum(df_points$label)

```

Foram feitos alguns gráficos iniciais que não estão inclusos, pois não forneceram nenhuma informação pertinente.

A partir desta análise, verifica-se que a base é equilibrada com relação à variável de interesse "label", ou seja, praticamente metade do banco de dados possui valor zero nessa variável (4973 zeros e 5027 uns). Dessa forma, a divisão da base em treino e teste é direta, não sendo necessários passos intermediários nesse processo.


Dividindo a base em treino e teste:

```{r}

train1 <- df_points[1:8000, ]
test1 <- df_points[8001:10000, ]

```

Como a base possui metade das respostas "zero" e a outra metade "um", é possível simplesmente separar a base pegando suas primeiras 8000 linhas como treino e as 2000 restantes como teste. Desta forma, temos 80% da base para treinar o modelo, ensinando a ele o que tem como resposta "um" e o que tem como resposta "zero" e 20% da base para testar se o modelo conseguiu captar o comportamento dos dados.


Regressão Logística:

```{r}

library(pscl)
regression <- glm(label ~ ., family = binomial(link = 'logit'), data = train)
regSummary <- summary(regression)
regAnova <- anova(regression, test="Chisq")
pR2(regression)

```

Utilizando um modelo de regressão logística, observa-se que nenhuma das variáveis é estatisticamente significativa, ou seja, nenhuma das três variáveis faz uma diferença significativa na classificação da observação como "um" ou "zero", um modelo sem uma dessas variáveis classificaria a observação da mesma forma.

Depois disso, o interesse é testar como o modelo está se comportando ao tentar classificar a variável "label" em uma nova base de dados. 


```{r}

fitted.results <- predict(regression,newdata = subset(test1, select = c(1, 2, 3)), type = 'response')
fitted.results <- ifelse(fitted.results > 0.5,1,0)

misClasificError <- mean(fitted.results != test1$label)
print(paste('Accuracy', 1-misClasificError))

```

O valor da acurácia do modelo é de 0,552 o que significa que o modelo classificou corretamente apenas metade dos dados o que não é um bom sinal, pois poderíamos jogar uma moeda e atribuir um valor para cada lado desta a cada observação e o resultado provavelmente seria o mesmo.

Antes de começar o outro método, vamos dividir a base de outra forma. Embora a base esteja equilibrada e a posição das respostas aparente ser aleatória, devemos testar outro método de divisão da base em teste e treino, pois o primeiro modelo não foi satisfatório.


Redivisão da base de dados:

```{r}

set.seed(1953)
TrainSet <- sample(nrow(df_points), 0.8*nrow(df_points), replace = FALSE)
train2 <- df_points[TrainSet, ]
test2 <- df_points[-TrainSet, ]
summary(train2)
summary(test2)

```

A base foi dividida de maneira aleatória desta vez e dessa outra forma foi colocada uma semente, para que toda vez que o código seja rodado, a base não seja diferente. Novamente a base foi dividida em 80% para treino e 20% para teste.

Floresta Aleatória:

```{r}

library(randomForest)
library(caret)
florest1 <- randomForest(label ~ ., data = train2, importance = TRUE)
florest1
florest2 <- randomForest(label ~ ., data = train2, ntree = 500, mtry = 2, importance = TRUE)
florest2

predTrain <- predict(florest1, train2, type = "class")
table(predTrain, train2$label)

predValid <- predict(florest1, test2, type = "class")
table(predValid, test2$label)

importance(florest1)        
varImpPlot(florest1)

```

Em modelos de floresta aleatória, o melhor número de variáveis tentada a cada divisão feita pelo modelo é a raíz quadrada do número de variáveis (que neste caso é 3) assim, o número ideal é de apenas uma variável por divisão.

Por ser uma base com um número pequeno de variáveis, este tipo de modelo não se mostrou melhor que o primeiro.

Comparando os dois modelos, nenhum dos dois se mostrou adequado, pois as informações não possuem correlação entre si e nenhuma variável se mostrou estatisticamente significativa em nenhum dos modelos. Sendo assim, a presença ou a ausência de uma daquelas variáveis não parece fazer diferença em nenhum dos dois modelos, não ajudando na classicação de suas observações.

A diferença dos dois modelos no caso é a interpretabilidade, sendo que a regressão logística é mais simples de se explicar. 
